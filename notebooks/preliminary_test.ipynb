{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('Master Thesis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3c2600dbb85c8b27e6e50cf4efdfd636baef57dd544fb148253cb17e6ab0fd06"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import qubit\n",
    "#!pip install git+https://github.com/Xergon-sci/Qubit.git@development\n",
    "from qubit.preprocessing.descriptors import tensorise_coulomb_matrix\n",
    "from qubit.preprocessing.matrix_operations import pad_matrix\n",
    "\n",
    "sys.path.append(r'C:\\Users\\Michiel Jacobs\\Research\\Master Thesis\\Experimental-Reactivity-Prediction\\code\\utilities')\n",
    "\n",
    "from data_utility import loaddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "data = loaddata(r'C:\\Users\\Michiel Jacobs\\Research\\Master Thesis\\Experimental-Reactivity-Prediction\\data')\n",
    "data = data[['coulomb_matrix', 'zero_point_energy']]\n",
    "# pandas loads data as list convert it to numpy arrays\n",
    "data['coulomb_matrix'] = data['coulomb_matrix'].apply(lambda x: np.array(x))\n",
    "# shuffle the data\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "# for development\n",
    "develop = True\n",
    "if develop:\n",
    "    data = data.iloc[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data set contains molecules with maximum 20 heavy atoms\n",
    "# So XnH2n+2 can be used to calculate the maximum atoms that can be present and thus\n",
    "# the maximum shape of our molecules\n",
    "n = 20\n",
    "maxsize = n + ((2*n)+2)\n",
    "\n",
    "# formalize the data to a constant size\n",
    "data['coulomb_matrix'] = data['coulomb_matrix'].apply(pad_matrix, size=maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorize the data ===== takes long time since arrays are padded and so bigger\n",
    "data['tensors'] = data['coulomb_matrix'].apply(tensorise_coulomb_matrix, negative_dimensions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap the matrix to provide channels\n",
    "data['features'] = data['tensors'].apply(np.expand_dims, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETLENGHT = data.shape[0]\n",
    "train_size = int(0.75 * DATASETLENGHT)\n",
    "# test size is whatever is left after the 0.75 split\n",
    "\n",
    "# split into train,val and test sets.\n",
    "train = data.iloc[:train_size,:]\n",
    "test = data.iloc[train_size+1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to make a np array filled with tensorflow tensors\n",
    "train_tensor_list = []\n",
    "for t in train['features'].values:\n",
    "    t = tf.convert_to_tensor(t)\n",
    "    train_tensor_list.append(t)\n",
    "\n",
    "test_tensor_list = []\n",
    "for t in test['features'].values:\n",
    "    t = tf.convert_to_tensor(t)\n",
    "    test_tensor_list.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (6,62,62,1)\n",
    "batch_size = 128\n",
    "kernel_size = (1,3,3)\n",
    "pool_size = (2,2,2)\n",
    "filters = 64\n",
    "dropout = 0.2\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Conv3D(\n",
    "    filters=filters,\n",
    "    kernel_size=kernel_size,\n",
    "    activation = 'relu',\n",
    "    input_shape = input_shape))\n",
    "model.add(layers.MaxPool3D(pool_size))\n",
    "model.add(layers.Conv3D(\n",
    "    filters=filters,\n",
    "    kernel_size=kernel_size,\n",
    "    activation = 'relu'))\n",
    "model.add(layers.MaxPool3D(pool_size))\n",
    "model.add(layers.Conv3D(\n",
    "    filters=filters,\n",
    "    kernel_size=kernel_size,\n",
    "    activation = 'relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv3d (Conv3D)              (None, 6, 60, 60, 64)     640       \n_________________________________________________________________\nmax_pooling3d (MaxPooling3D) (None, 3, 30, 30, 64)     0         \n_________________________________________________________________\nconv3d_1 (Conv3D)            (None, 3, 28, 28, 64)     36928     \n_________________________________________________________________\nmax_pooling3d_1 (MaxPooling3 (None, 1, 14, 14, 64)     0         \n_________________________________________________________________\nconv3d_2 (Conv3D)            (None, 1, 12, 12, 64)     36928     \n_________________________________________________________________\nflatten (Flatten)            (None, 9216)              0         \n_________________________________________________________________\ndropout (Dropout)            (None, 9216)              0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 9217      \n=================================================================\nTotal params: 83,713\nTrainable params: 83,713\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0000e+00 - accuracy: 0.0000e+00 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "1/1 - 1s - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "Test loss: 0.0\n",
      "Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "zpe = train['zero_point_energy'].values.astype(np.float).tolist()\n",
    "zpe = np.array(zpe)\n",
    "\n",
    "history = model.fit(\n",
    "    np.array(train_tensor_list),\n",
    "    zpe,\n",
    "    batch_size=512,\n",
    "    epochs=2,\n",
    "    validation_split=0.2)\n",
    "\n",
    "test_zpe = test['zero_point_energy'].values.astype(np.float).tolist()\n",
    "test_zpe = np.array(test_zpe)\n",
    "\n",
    "test_scores = model.evaluate(\n",
    "    np.array(test_tensor_list),\n",
    "    test_zpe,\n",
    "    verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': [0.0, 0.0],\n",
       " 'accuracy': [0.0, 0.0],\n",
       " 'val_loss': [0.0, 0.0],\n",
       " 'val_accuracy': [0.0, 0.0]}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(24,)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "test_zpe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"path_to_my_model\")\n",
    "#del model"
   ]
  }
 ]
}